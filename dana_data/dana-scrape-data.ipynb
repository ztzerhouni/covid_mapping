{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping tweets from El Paso, Lubbock, Amarillo, Laredo, Odessa, and Aberline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import GetOldTweets3 as got\n",
    "import time\n",
    "from calendar import Calendar, monthrange\n",
    "from datetime import datetime, timedelta\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to request tweets within a certain time period\n",
    "def get_tweets(query, since, until, max_tweets,location, radius):\n",
    "    # Set our tweet criteria using GetOldTweets3\n",
    "    tweetCriteria = got.manager.TweetCriteria()\\\n",
    "                                            .setQuerySearch(query)\\\n",
    "                                            .setSince(since)\\\n",
    "                                            .setUntil(until)\\\n",
    "                                            .setMaxTweets(max_tweets)\\\n",
    "                                            .setNear(location)\\\n",
    "                                            .setWithin(radius)\n",
    "    \n",
    "    tweet = got.manager.TweetManager.getTweets(tweetCriteria)\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df(tweet):\n",
    "    total_list = []\n",
    "    for i in range(len(tweet)):\n",
    "        my_dict = {\n",
    "            \"id\" : tweet[i].id,\n",
    "            \"text\" : tweet[i].text,\n",
    "            \"date\" : tweet[i].date,\n",
    "            \"retweets\" : tweet[i].retweets,\n",
    "            \"favorites\" : tweet[i].favorites,\n",
    "            \"mentions\" : tweet[i].mentions,\n",
    "            \"hashtags\" : tweet[i].hashtags,\n",
    "            \"geo\" : tweet[i].geo  \n",
    "        }\n",
    "        total_list.append(my_dict)\n",
    "    return pd.DataFrame(total_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "since_list = [\"2020-08-30\", \"2020-08-31\", \"2020-09-01\", \"2020-09-02\", \"2020-09-03\", \"2020-09-04\", \"2020-09-05\"]\n",
    "\n",
    "until_list = [\"2020-08-31\", \"2020-09-01\", \"2020-09-02\", \"2020-09-03\", \"2020-09-04\", \"2020-09-05\",\"2020-09-06\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_tweets(region, query, since, until,\n",
    "                max_tweets, location, radius):\n",
    "    t0 = time.time() \n",
    "    df = pd.DataFrame()\n",
    "    for i in range(len(since)):\n",
    "        x = get_tweets(query=query,\n",
    "                   since=since[i],\n",
    "                   until=until[i],\n",
    "                   max_tweets = max_tweets,\n",
    "                   location = location,\n",
    "                   radius = radius\n",
    "                  )\n",
    "        df = pd.concat([df,create_df(x)])\n",
    "        print(f\"Index {i}: day {since_list[i]} complete at {t0 - time.time()} seconds\")\n",
    "        if i < len(since)-1:\n",
    "            time.sleep(60)\n",
    "    print(f\"Final run time: {t0 - time.time()} seconds\")\n",
    "    df[\"region\"] = region\n",
    "    df.to_csv(f\"{region}_data.csv\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index 0: day 2020-08-30 complete at -55.494654417037964 seconds\n",
      "Index 1: day 2020-08-31 complete at -175.6429831981659 seconds\n",
      "Index 2: day 2020-09-01 complete at -293.6534070968628 seconds\n",
      "Index 3: day 2020-09-02 complete at -413.12114930152893 seconds\n",
      "Index 4: day 2020-09-03 complete at -532.5497512817383 seconds\n",
      "Index 5: day 2020-09-04 complete at -652.437087059021 seconds\n",
      "Index 6: day 2020-09-05 complete at -769.1250152587891 seconds\n",
      "Final run time: -769.1250152587891 seconds\n"
     ]
    }
   ],
   "source": [
    "el_paso = all_tweets(\n",
    "                region =  \"El_Paso\",\n",
    "                query = ' ',\n",
    "                since = since_list,\n",
    "                until = until_list,\n",
    "                max_tweets = 2000,\n",
    "                location = \"31.7619, -106.4850\",\n",
    "                radius = \"20mi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "el_paso_covid = el_paso['text'].str.contains('covid|coronavirus', flags=re.IGNORECASE, regex=True).sum()\n",
    "el_paso_covid\n",
    "\n",
    "#s1.str.contains('PARROT', flags=re.IGNORECASE, regex=True)\n",
    "#mel_count=a['Names'].str.contains('Mel').sum()\n",
    "#https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.str.contains.html#pandas.Series.str.contains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index 0: day 2020-08-30 complete at -21.305082321166992 seconds\n",
      "Index 1: day 2020-08-31 complete at -105.15097951889038 seconds\n",
      "Index 2: day 2020-09-01 complete at -188.64397144317627 seconds\n",
      "Index 3: day 2020-09-02 complete at -272.37101793289185 seconds\n",
      "Index 4: day 2020-09-03 complete at -355.7938964366913 seconds\n",
      "Index 5: day 2020-09-04 complete at -440.66676688194275 seconds\n",
      "Index 6: day 2020-09-05 complete at -557.369528055191 seconds\n",
      "Final run time: -557.369528055191 seconds\n"
     ]
    }
   ],
   "source": [
    "lubbock = all_tweets(\n",
    "                region =  \"Lubbock\",\n",
    "                query = ' ',\n",
    "                since = since_list,\n",
    "                until = until_list,\n",
    "                max_tweets = 2000,\n",
    "                location = \"33.5779, -101.8552\",\n",
    "                radius = \"12mi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lubbock_covid= lubbock['text'].str.contains('covid|coronavirus', flags=re.IGNORECASE, regex=True).sum()\n",
    "lubbock_covid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index 0: day 2020-08-30 complete at -5.924284219741821 seconds\n",
      "Index 1: day 2020-08-31 complete at -73.04520177841187 seconds\n",
      "Index 2: day 2020-09-01 complete at -141.26595616340637 seconds\n",
      "Index 3: day 2020-09-02 complete at -209.47456884384155 seconds\n",
      "Index 4: day 2020-09-03 complete at -279.32396626472473 seconds\n",
      "Index 5: day 2020-09-04 complete at -348.95183300971985 seconds\n",
      "Index 6: day 2020-09-05 complete at -462.9198319911957 seconds\n",
      "Final run time: -462.9198319911957 seconds\n"
     ]
    }
   ],
   "source": [
    "amarillo = all_tweets(\n",
    "                region =  \"Amarillo\",\n",
    "                query = ' ',\n",
    "                since = since_list,\n",
    "                until = until_list,\n",
    "                max_tweets = 2000,\n",
    "                location = \"35.2220, -101.8313\",\n",
    "                radius = \"13mi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amarillo_covid = amarillo['text'].str.contains('covid|coronavirus', flags=re.IGNORECASE, regex=True).sum()\n",
    "amarillo_covid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index 0: day 2020-08-30 complete at -9.5302414894104 seconds\n",
      "Index 1: day 2020-08-31 complete at -80.47281980514526 seconds\n",
      "Index 2: day 2020-09-01 complete at -153.67202138900757 seconds\n",
      "Index 3: day 2020-09-02 complete at -224.20110297203064 seconds\n",
      "Index 4: day 2020-09-03 complete at -296.73204231262207 seconds\n",
      "Index 5: day 2020-09-04 complete at -369.489529132843 seconds\n",
      "Index 6: day 2020-09-05 complete at -484.9079625606537 seconds\n",
      "Final run time: -484.9089596271515 seconds\n"
     ]
    }
   ],
   "source": [
    "laredo = all_tweets(\n",
    "                region =  \"Laredo\",\n",
    "                query = ' ',\n",
    "                since = since_list,\n",
    "                until = until_list,\n",
    "                max_tweets = 2000,\n",
    "                location = \"27.5199841,-99.4953764\",\n",
    "                radius = \"9mi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "laredo_covid = laredo['text'].str.contains('covid|coronavirus', flags=re.IGNORECASE, regex=True).sum()\n",
    "laredo_covid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index 0: day 2020-08-30 complete at -4.749912738800049 seconds\n",
      "Index 1: day 2020-08-31 complete at -72.40460681915283 seconds\n",
      "Index 2: day 2020-09-01 complete at -142.0024437904358 seconds\n",
      "Index 3: day 2020-09-02 complete at -209.2247281074524 seconds\n",
      "Index 4: day 2020-09-03 complete at -278.6753468513489 seconds\n",
      "Index 5: day 2020-09-04 complete at -347.9718837738037 seconds\n",
      "Index 6: day 2020-09-05 complete at -461.8415994644165 seconds\n",
      "Final run time: -461.8415994644165 seconds\n"
     ]
    }
   ],
   "source": [
    "odessa = all_tweets(\n",
    "                region =  \"Odessa\",\n",
    "                query = ' ',\n",
    "                since = since_list,\n",
    "                until = until_list,\n",
    "                max_tweets = 2000,\n",
    "                location = \"31.8457, -102.3676\",\n",
    "                radius = \"14mi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "odessa_covid = odessa['text'].str.contains('covid|coronavirus', flags=re.IGNORECASE, regex=True).sum()\n",
    "odessa_covid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index 0: day 2020-08-30 complete at -9.042999029159546 seconds\n",
      "Index 1: day 2020-08-31 complete at -80.21705770492554 seconds\n",
      "Index 2: day 2020-09-01 complete at -151.27152585983276 seconds\n",
      "Index 3: day 2020-09-02 complete at -219.85091471672058 seconds\n",
      "Index 4: day 2020-09-03 complete at -289.92616605758667 seconds\n",
      "Index 5: day 2020-09-04 complete at -361.370646238327 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occured during an HTTP request: [WinError 10053] An established connection was aborted by the software in your host machine\n",
      "Try to open in browser: https://twitter.com/search?q=%20%20near%3A%2232.4487%2C%20-99.7331%22%20within%3A9mi%20since%3A2020-09-05%20until%3A2020-09-06&src=typd\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\12155\\anaconda3\\lib\\site-packages\\GetOldTweets3\\manager\\TweetManager.py\", line 344, in getJsonResponse\n",
      "    jsonResponse = response.read()\n",
      "  File \"C:\\Users\\12155\\anaconda3\\lib\\http\\client.py\", line 470, in read\n",
      "    s = self._safe_read(self.length)\n",
      "  File \"C:\\Users\\12155\\anaconda3\\lib\\http\\client.py\", line 620, in _safe_read\n",
      "    chunk = self.fp.read(min(amt, MAXAMOUNT))\n",
      "  File \"C:\\Users\\12155\\anaconda3\\lib\\socket.py\", line 589, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"C:\\Users\\12155\\anaconda3\\lib\\ssl.py\", line 1071, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"C:\\Users\\12155\\anaconda3\\lib\\ssl.py\", line 929, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "ConnectionAbortedError: [WinError 10053] An established connection was aborted by the software in your host machine\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\12155\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3331, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-28-485c98d2258d>\", line 8, in <module>\n",
      "    radius = \"9mi\")\n",
      "  File \"<ipython-input-16-b51ef92beaec>\", line 11, in all_tweets\n",
      "    radius = radius\n",
      "  File \"<ipython-input-13-6f42af546d1f>\", line 12, in get_tweets\n",
      "    tweet = got.manager.TweetManager.getTweets(tweetCriteria)\n",
      "  File \"C:\\Users\\12155\\anaconda3\\lib\\site-packages\\GetOldTweets3\\manager\\TweetManager.py\", line 65, in getTweets\n",
      "    json = TweetManager.getJsonResponse(tweetCriteria, refreshCursor, cookieJar, proxy, user_agent, debug=debug)\n",
      "  File \"C:\\Users\\12155\\anaconda3\\lib\\site-packages\\GetOldTweets3\\manager\\TweetManager.py\", line 348, in getJsonResponse\n",
      "    sys.exit()\n",
      "SystemExit\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\12155\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1151, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\12155\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 319, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\12155\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 353, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\12155\\anaconda3\\lib\\inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "AttributeError: 'tuple' object has no attribute 'tb_frame'\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mSystemExit\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "abilene = all_tweets(\n",
    "                region =  \"Abilene\",\n",
    "                query = ' ',\n",
    "                since = since_list,\n",
    "                until = until_list,\n",
    "                max_tweets = 2000,\n",
    "                location = \"32.4487, -99.7331\",\n",
    "                radius = \"9mi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abilene_covid = abilene['text'].str.contains('covid|coronavirus', flags=re.IGNORECASE, regex=True).sum()\n",
    "abilene_covid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
