{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.datasets import make_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('zak_data/clean_dallas.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['text']\n",
    "y = df['counts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9146</th>\n",
       "      <td>that fucking sack of orange shit has pissed me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3709</th>\n",
       "      <td>Last goal.....literally the last goal of the y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4370</th>\n",
       "      <td>Oh Trump definitely has a plan. Eliminate test...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6711</th>\n",
       "      <td>Some are off on covid leave. So they are being...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14475</th>\n",
       "      <td>The rise in young, black home ownership is dop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10955</th>\n",
       "      <td>@marklevinshow was talking about ur coronaviru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17289</th>\n",
       "      <td>\"Kamala Harris delivers remarks on COVID-19 pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5192</th>\n",
       "      <td>If you need masks, gloves, sanitizer etc check...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12172</th>\n",
       "      <td>First COVID-19 vaccine tested in the US shows ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>The CIA, FAA, France, and Rita Wilson warn abo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13854 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text\n",
       "9146   that fucking sack of orange shit has pissed me...\n",
       "3709   Last goal.....literally the last goal of the y...\n",
       "4370   Oh Trump definitely has a plan. Eliminate test...\n",
       "6711   Some are off on covid leave. So they are being...\n",
       "14475  The rise in young, black home ownership is dop...\n",
       "...                                                  ...\n",
       "10955  @marklevinshow was talking about ur coronaviru...\n",
       "17289  \"Kamala Harris delivers remarks on COVID-19 pa...\n",
       "5192   If you need masks, gloves, sanitizer etc check...\n",
       "12172  First COVID-19 vaccine tested in the US shows ...\n",
       "235    The CIA, FAA, France, and Rita Wilson warn abo...\n",
       "\n",
       "[13854 rows x 1 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvec = CountVectorizer()\n",
    "cvec.fit_transform(X_train)\n",
    "X_train_cvec = cvec.transform(X_train)\n",
    "X_train_df = pd.DataFrame(X_train_cvec.toarray(),\n",
    "                          columns=cvec.get_feature_names()\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>0003</th>\n",
       "      <th>00033</th>\n",
       "      <th>000502857142857</th>\n",
       "      <th>000512</th>\n",
       "      <th>0007</th>\n",
       "      <th>001</th>\n",
       "      <th>0027</th>\n",
       "      <th>003_osp</th>\n",
       "      <th>...</th>\n",
       "      <th>ไปท</th>\n",
       "      <th>에이티즈</th>\n",
       "      <th>𝐛𝐞</th>\n",
       "      <th>𝐜𝐥𝐨𝐬𝐞𝐝</th>\n",
       "      <th>𝐟𝐨𝐫</th>\n",
       "      <th>𝐭𝐡𝐞</th>\n",
       "      <th>𝐰𝐞</th>\n",
       "      <th>𝐰𝐢𝐥𝐥</th>\n",
       "      <th>𝔻𝕚𝕞𝕖𝕟𝕤𝕚𝕠𝕟𝕒𝕝</th>\n",
       "      <th>𝕓𝕝𝕠𝕟𝕕𝕖</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13849</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13850</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13851</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13852</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13853</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13854 rows × 28845 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       00  000  0003  00033  000502857142857  000512  0007  001  0027  \\\n",
       "0       0    0     0      0                0       0     0    0     0   \n",
       "1       0    0     0      0                0       0     0    0     0   \n",
       "2       0    0     0      0                0       0     0    0     0   \n",
       "3       0    0     0      0                0       0     0    0     0   \n",
       "4       0    0     0      0                0       0     0    0     0   \n",
       "...    ..  ...   ...    ...              ...     ...   ...  ...   ...   \n",
       "13849   0    0     0      0                0       0     0    0     0   \n",
       "13850   0    0     0      0                0       0     0    0     0   \n",
       "13851   0    0     0      0                0       0     0    0     0   \n",
       "13852   0    0     0      0                0       0     0    0     0   \n",
       "13853   0    0     0      0                0       0     0    0     0   \n",
       "\n",
       "       003_osp  ...  ไปท  에이티즈  𝐛𝐞  𝐜𝐥𝐨𝐬𝐞𝐝  𝐟𝐨𝐫  𝐭𝐡𝐞  𝐰𝐞  𝐰𝐢𝐥𝐥  𝔻𝕚𝕞𝕖𝕟𝕤𝕚𝕠𝕟𝕒𝕝  \\\n",
       "0            0  ...    0     0   0       0    0    0   0     0            0   \n",
       "1            0  ...    0     0   0       0    0    0   0     0            0   \n",
       "2            0  ...    0     0   0       0    0    0   0     0            0   \n",
       "3            0  ...    0     0   0       0    0    0   0     0            0   \n",
       "4            0  ...    0     0   0       0    0    0   0     0            0   \n",
       "...        ...  ...  ...   ...  ..     ...  ...  ...  ..   ...          ...   \n",
       "13849        0  ...    0     0   0       0    0    0   0     0            0   \n",
       "13850        0  ...    0     0   0       0    0    0   0     0            0   \n",
       "13851        0  ...    0     0   0       0    0    0   0     0            0   \n",
       "13852        0  ...    0     0   0       0    0    0   0     0            0   \n",
       "13853        0  ...    0     0   0       0    0    0   0     0            0   \n",
       "\n",
       "       𝕓𝕝𝕠𝕟𝕕𝕖  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  \n",
       "...       ...  \n",
       "13849       0  \n",
       "13850       0  \n",
       "13851       0  \n",
       "13852       0  \n",
       "13853       0  \n",
       "\n",
       "[13854 rows x 28845 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('cvec', CountVectorizer()),\n",
       "                                       ('tfidf', TfidfTransformer()),\n",
       "                                       ('lr', LinearRegression())]),\n",
       "             param_grid={})"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "    ('cvec', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('lr', LinearRegression())\n",
    "])\n",
    "\n",
    "pipe_params = {\n",
    "    \n",
    "}\n",
    "\n",
    "gs = GridSearchCV(pipe,\n",
    "                   param_grid = pipe_params,\n",
    "                   cv=5)\n",
    "\n",
    "gs.fit(X_train,y_train)\n",
    "\n",
    "print(f'Training Score: {gs.score(X_train,y_train)}')\n",
    "print(f'Testing Score: {gs.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9892661197277993"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(gs.score(X_train,y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-665.5009528573495"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:    4.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:    4.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.4764089940666961\n",
      "Testing Score: -0.31565905921133264\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "    ('cvec', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('lr', LinearRegression())\n",
    "])\n",
    "\n",
    "pipe_params = {\n",
    "# Vectorizer Options\n",
    " 'cvec__analyzer': ['word'],\n",
    " 'cvec__binary': [False],\n",
    " 'cvec__decode_error': ['strict'],\n",
    " 'cvec__encoding': ['utf-8'],\n",
    " 'cvec__input': ['content'],\n",
    " 'cvec__lowercase': [True],\n",
    " 'cvec__max_df': [1.0],\n",
    " 'cvec__max_features': [5000],\n",
    " 'cvec__min_df': [1],\n",
    " 'cvec__ngram_range': [(1, 1)],\n",
    " 'cvec__preprocessor': [None],\n",
    " 'cvec__stop_words': [None],\n",
    " 'cvec__strip_accents': [None],\n",
    " 'cvec__token_pattern': ['(?u)\\\\b\\\\w\\\\w+\\\\b'],\n",
    " 'cvec__tokenizer': [None],\n",
    " 'cvec__vocabulary': [None],\n",
    "# Transformer Options\n",
    " 'tfidf__norm': ['l2'],\n",
    " 'tfidf__smooth_idf': [True],\n",
    " 'tfidf__sublinear_tf': [False],\n",
    " 'tfidf__use_idf': [True],\n",
    "# Linear Regression Options\n",
    " 'lr__copy_X': [True],\n",
    " 'lr__fit_intercept': [True],\n",
    " 'lr__n_jobs': [None],\n",
    " 'lr__normalize': [False]\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(pipe,\n",
    "                   param_grid = pipe_params,\n",
    "                   cv=5,\n",
    "                  n_jobs=2,\n",
    "                  verbose = 2)\n",
    "\n",
    "gs.fit(X_train,y_train)\n",
    "\n",
    "print(f'Training Score: {gs.score(X_train,y_train)}')\n",
    "print(f'Testing Score: {gs.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('cvec', CountVectorizer()),\n",
       "  ('tfidf', TfidfTransformer()),\n",
       "  ('lr', LinearRegression())],\n",
       " 'verbose': False,\n",
       " 'cvec': CountVectorizer(),\n",
       " 'tfidf': TfidfTransformer(),\n",
       " 'lr': LinearRegression(),\n",
       " 'cvec__analyzer': 'word',\n",
       " 'cvec__binary': False,\n",
       " 'cvec__decode_error': 'strict',\n",
       " 'cvec__dtype': numpy.int64,\n",
       " 'cvec__encoding': 'utf-8',\n",
       " 'cvec__input': 'content',\n",
       " 'cvec__lowercase': True,\n",
       " 'cvec__max_df': 1.0,\n",
       " 'cvec__max_features': None,\n",
       " 'cvec__min_df': 1,\n",
       " 'cvec__ngram_range': (1, 1),\n",
       " 'cvec__preprocessor': None,\n",
       " 'cvec__stop_words': None,\n",
       " 'cvec__strip_accents': None,\n",
       " 'cvec__token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       " 'cvec__tokenizer': None,\n",
       " 'cvec__vocabulary': None,\n",
       " 'tfidf__norm': 'l2',\n",
       " 'tfidf__smooth_idf': True,\n",
       " 'tfidf__sublinear_tf': False,\n",
       " 'tfidf__use_idf': True,\n",
       " 'lr__copy_X': True,\n",
       " 'lr__fit_intercept': True,\n",
       " 'lr__n_jobs': None,\n",
       " 'lr__normalize': False}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:  2.1min remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:  2.1min finished\n",
      "/Users/zakz/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.2267655171351115\n",
      "Testing Score: 0.02317202807429042\n",
      "Best Params: {'cvec__max_features': 1000, 'cvec__ngram_range': (1, 1)}\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "    ('cvec', CountVectorizer()),\n",
    "    ('MLP', MLPRegressor(hidden_layer_sizes=(3,), activation ='relu',\n",
    "         solver='adam', alpha=0.001, batch_size='auto',\n",
    "         learning_rate='adaptive', learning_rate_init=0.01,\n",
    "         power_t=0.5, max_iter=1000, shuffle=True, random_state=9,\n",
    "         tol=0.0001, verbose=False, warm_start=False, momentum=0.9,\n",
    "         nesterovs_momentum=True, early_stopping=False,\n",
    "         validation_fraction=0.1, beta_1=0.9, beta_2=0.999,\n",
    "         epsilon=1e-08))\n",
    "])\n",
    "\n",
    "pipe_params = {\n",
    "    'cvec__ngram_range': [(1, 1), (1,2)],\n",
    "    'cvec__max_features': [1000, 3000, 5000],\n",
    "    \n",
    "}\n",
    "\n",
    "gs = GridSearchCV(pipe,\n",
    "                   param_grid = pipe_params,\n",
    "                   cv=5, n_jobs=2, verbose = 2)\n",
    "\n",
    "gs.fit(X_train,y_train)\n",
    "print(f'Training Score: {gs.score(X_train,y_train)}')\n",
    "print(f'Testing Score: {gs.score(X_test, y_test)}')\n",
    "print(f'Best Params: {gs.best_params_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.16613476370855107\n",
      "Testing Score: 0.03894265660739582\n"
     ]
    }
   ],
   "source": [
    "print(f'Training Score: {gs.score(X_train,y_train)}')\n",
    "print(f'Testing Score: {gs.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('cvec', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('MLP', MLPRegressor(hidden_layer_sizes=(3,), activation ='relu',\n",
    "         solver='adam', alpha=0.001, batch_size='auto',\n",
    "         learning_rate='adaptive', learning_rate_init=0.01,\n",
    "         power_t=0.5, max_iter=1000, shuffle=True, random_state=9,\n",
    "         tol=0.0001, verbose=False, warm_start=False, momentum=0.9,\n",
    "         nesterovs_momentum=True, early_stopping=False,\n",
    "         validation_fraction=0.1, beta_1=0.9, beta_2=0.999,\n",
    "         epsilon=1e-08))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cvec__max_features': 1000, 'cvec__ngram_range': (1, 1)}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('cvec', CountVectorizer()),\n",
       "  ('tfidf', TfidfTransformer()),\n",
       "  ('MLP', LinearRegression())],\n",
       " 'verbose': False,\n",
       " 'cvec': CountVectorizer(),\n",
       " 'tfidf': TfidfTransformer(),\n",
       " 'MLP': LinearRegression(),\n",
       " 'cvec__analyzer': 'word',\n",
       " 'cvec__binary': False,\n",
       " 'cvec__decode_error': 'strict',\n",
       " 'cvec__dtype': numpy.int64,\n",
       " 'cvec__encoding': 'utf-8',\n",
       " 'cvec__input': 'content',\n",
       " 'cvec__lowercase': True,\n",
       " 'cvec__max_df': 1.0,\n",
       " 'cvec__max_features': None,\n",
       " 'cvec__min_df': 1,\n",
       " 'cvec__ngram_range': (1, 1),\n",
       " 'cvec__preprocessor': None,\n",
       " 'cvec__stop_words': None,\n",
       " 'cvec__strip_accents': None,\n",
       " 'cvec__token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       " 'cvec__tokenizer': None,\n",
       " 'cvec__vocabulary': None,\n",
       " 'tfidf__norm': 'l2',\n",
       " 'tfidf__smooth_idf': True,\n",
       " 'tfidf__sublinear_tf': False,\n",
       " 'tfidf__use_idf': True,\n",
       " 'MLP__copy_X': True,\n",
       " 'MLP__fit_intercept': True,\n",
       " 'MLP__n_jobs': None,\n",
       " 'MLP__normalize': False}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  30 out of  30 | elapsed: 57.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.8596347671415592\n",
      "Testing Score: 0.09173843797652104\n",
      "Best Params: {'cvec__max_features': 1000, 'cvec__ngram_range': (1, 1)}\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "    ('cvec', CountVectorizer()),\n",
    "    ('rf', RandomForestRegressor())\n",
    "])\n",
    "\n",
    "pipe_params = {\n",
    "    'cvec__ngram_range': [(1, 1), (1,2)],\n",
    "    'cvec__max_features': [1000, 3000, 5000],\n",
    "    \n",
    "}\n",
    "\n",
    "gs = GridSearchCV(pipe,\n",
    "                   param_grid = pipe_params,\n",
    "                   cv=5, n_jobs=2, verbose = 2)\n",
    "\n",
    "gs.fit(X_train,y_train)\n",
    "print(f'Training Score: {gs.score(X_train,y_train)}')\n",
    "print(f'Testing Score: {gs.score(X_test, y_test)}')\n",
    "print(f'Best Params: {gs.best_params_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
